# gated_page_scraper.py
# =============================================================================
# ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæå‡ºç”¨ãƒ»åŒ¿ååŒ–æ¸ˆã¿ã‚µãƒ³ãƒ—ãƒ«ã€‘
# - ä¼šå“¡åˆ¶ã‚µã‚¤ãƒˆï¼ˆè‡ªåˆ†ãŒåˆ©ç”¨æ¨©é™ã‚’æŒã¤ã‚µã‚¤ãƒˆï¼‰ã«å¯è¦–ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ­ã‚°ã‚¤ãƒ³
# - ã‚»ãƒƒã‚·ãƒ§ãƒ³Cookieã‚’Playwrightã¸å—ã‘æ¸¡ã—ã€ç¯€åº¦ã‚ã‚‹QPSã§ãƒ¡ãƒ³ãƒãƒ¼ãƒšãƒ¼ã‚¸ã‚’å·¡å›
# - å®Ÿã‚µã‚¤ãƒˆãƒ»ç¤¾åãƒ»éŠ˜æŸ„ãƒ»URLãƒ»XPathã¯ã™ã¹ã¦ãƒ€ãƒŸãƒ¼ï¼ˆç‰¹å®šä¸å¯ï¼‰
# - è¦ç´„é †å®ˆã®ãŸã‚ã®å®‰å…¨è£…ç½®ï¼ˆæ˜ç¤ºã‚ªãƒ—ãƒˆã‚¤ãƒ³ã€è¨±å¯ã‚ªãƒªã‚¸ãƒ³ã€ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ã€æœ€å°ãƒ­ã‚°ç­‰ï¼‰
#
# âš  é‡è¦:
# - è‡ªå‹•åŒ–ã‚„å–å¾—ã¯ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ãƒ»æ³•ä»¤ãƒ»robotsç­‰ã«å¾“ã„ã€æ¨©é™ãŒã‚ã‚‹ç¯„å›²ã§ã®ã¿å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚
# - æœ¬ã‚³ãƒ¼ãƒ‰ã¯ã€Œã‚„ã‚ŠãŸã„ã“ã¨ãƒ»ç›®çš„ã€ã‚’ç¤ºã™ãŸã‚ã®é››å½¢ã§ã™ã€‚å®Ÿé‹ç”¨å‰ã«å¿…ãšæ³•å‹™/ã‚³ãƒ³ãƒ—ãƒ©ç¢ºèªã‚’ã€‚
# =============================================================================

import os
import re
import sys
import time
import sqlite3
import argparse
import datetime
from typing import Dict, Any, List, Tuple, Optional
from contextlib import asynccontextmanager

# --- Seleniumï¼ˆäººæ‰‹ãƒ­ã‚°ã‚¤ãƒ³ç”¨ã®å¯è¦–ãƒ–ãƒ©ã‚¦ã‚¶ï¼‰ -----------------------------------
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- Playwrightï¼ˆãƒ­ã‚°ã‚¤ãƒ³å¾Œã®åŠ¹ç‡çš„ãªå–å¾—ï¼‰ ---------------------------------------
import asyncio
from playwright.async_api import async_playwright, TimeoutError as PwTimeout, Page

# ====== ç’°å¢ƒå¤‰æ•°ï¼ˆæ˜ç¤ºã‚ªãƒ—ãƒˆã‚¤ãƒ³ & åŒ¿åï¼‰ =========================================
# è‡ªå‹•åŒ–ã®æ˜ç¤ºè¨±è«¾ï¼ˆæœªè¨­å®šãªã‚‰å®‰å…¨å´ã§åœæ­¢ï¼‰
ALLOW_AUTOMATION = os.getenv("ALLOW_AUTOMATION", "0") in ("1", "true", "TRUE", "yes", "YES")
# ID/PWã®è‡ªå‹•å…¥åŠ›ã‚’è¨±å¯ï¼ˆä»»æ„ã€‚æœªè¨±å¯ãªã‚‰äººæ‰‹ã§å…¥åŠ›ï¼‰
ALLOW_AUTOFILL   = os.getenv("ALLOW_AUTOFILL", "0") in ("1", "true", "TRUE", "yes", "YES")

# èªè¨¼æƒ…å ±ï¼ˆä»»æ„ãƒ»ãƒ€ãƒŸãƒ¼ï¼‰ã€‚ALLOW_AUTOFILL ãŒ True ã®æ™‚ã ã‘ä½¿ç”¨ã€‚
USER_ID   = os.getenv("GATED_USER_ID", "")
PASSWORD  = os.getenv("GATED_PASSWORD", "")

# å¯¾è±¡ã‚µã‚¤ãƒˆï¼ˆãƒ€ãƒŸãƒ¼ï¼‰ã€‚å…·ä½“åã¯å‡ºã•ãªã„ã€‚
LOGIN_URL   = os.getenv("GATED_LOGIN_URL",   "https://example.com/login")
BASE_ORIGIN = os.getenv("GATED_BASE_ORIGIN", "https://example.com")  # ç›¸å¯¾URLã®æ­£è¦åŒ–ç”¨

# DBãƒ‘ã‚¹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
DB_PATH = os.getenv("GATED_DB_PATH", os.path.abspath("./portfolio_demo.db"))

# å®Ÿè¡Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆä¿å®ˆçš„ãªæ—¢å®šå€¤ï¼‰
DEFAULT_CONCURRENCY = int(os.getenv("GATED_CONCURRENCY", "2"))
DEFAULT_QPS         = float(os.getenv("GATED_QPS", "0.6"))          # 0.6 req/sec
DEFAULT_BATCH       = int(os.getenv("GATED_BATCH", "100"))
NAV_TIMEOUT_MS      = int(os.getenv("GATED_NAV_TIMEOUT_MS", "25000"))
SEL_NAV_TIMEOUT     = int(os.getenv("GATED_SEL_NAV_TIMEOUT", "25"))
RETRIES             = int(os.getenv("GATED_RETRIES", "3"))
BASE_DELAY          = float(os.getenv("GATED_BASE_DELAY", "0.8"))
DEFAULT_LOGIN_WAIT  = int(os.getenv("GATED_LOGIN_WAIT", "60"))

# è¨±å¯ã‚ªãƒªã‚¸ãƒ³ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚ä¸€è‡´ã—ãªã„URLã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå®‰å…¨å´ï¼‰ã€‚
ALLOWED_ORIGINS = [o.strip() for o in os.getenv("GATED_ALLOWED_ORIGINS", BASE_ORIGIN).split(",") if o.strip()]

# ====== å–å¾—å¯¾è±¡ï¼ˆãƒ€ãƒŸãƒ¼XPathï¼šç›®çš„å…±æœ‰ã®ãŸã‚ã®æœ€å°æ§‹æˆï¼‰ ===========================
# ä¼šå“¡ãƒšãƒ¼ã‚¸ä¸Šã§ã€KPIã‚„ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’æ‹¾ã†ä¾‹ã€‚å®ŸDOMã«åˆã‚ã›ã¦å·®ã—æ›¿ãˆå‰æã€‚
XPATH_MAP: Dict[str, str] = {
    # KPIä¾‹
    "sales_growth":     "string(//*[@id='metrics']//table//tr[1]/td[2])",
    "op_profit_growth": "string(//*[@id='metrics']//table//tr[2]/td[2])",
    "op_margin":        "string(//*[@id='metrics']//table//tr[3]/td[2])",
    "roe":              "string(//*[@id='metrics']//table//tr[4]/td[2])",
    "roa":              "string(//*[@id='metrics']//table//tr[5]/td[2])",
    "equity_ratio":     "string(//*[@id='metrics']//table//tr[6]/td[2])",
    "dividend_payout":  "string(//*[@id='metrics']//table//tr[7]/td[2])",
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ä¾‹
    "overview_text":    "string(//*[@id='report']//div[@data-block='overview'])",
    "topics_text":      "string(//*[@id='report']//div[@data-block='topics'])",
    "risks_text":       "string(//*[@id='report']//div[@data-block='risks'])",
}

# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============================================================
def pct(s: str) -> str:
    """æœ«å°¾%ãŒç„¡ã‘ã‚Œã°ä»˜ä¸ï¼ˆä¾‹ç¤ºçš„æ•´å½¢ï¼‰"""
    s = (s or "").strip()
    if not s:
        return ""
    return s if s.endswith("%") else (s + "%")

def squeeze_ws(s: str) -> str:
    """å…¨è§’ç©ºç™½å«ã‚€é€£ç¶šç©ºç™½ã‚’1ã‚¹ãƒšãƒ¼ã‚¹ã¸åœ§ç¸®"""
    if not s:
        return ""
    return re.sub(r"\s+", " ", s.replace("\u3000", " ")).strip()

def is_allowed(url: str) -> bool:
    """è¨±å¯ã‚ªãƒªã‚¸ãƒ³ä»¥å¤–ã¯å–å¾—å¯¾è±¡å¤–ï¼ˆå®‰å…¨å´ï¼‰"""
    return any(url.startswith(origin) for origin in ALLOWED_ORIGINS)

def redact(s: str) -> str:
    """ãƒ­ã‚°ç”¨ã®ç°¡æ˜“ãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆPIIã‚„é•·æ•°å­—ã‚’ä¼ã›ã‚‹ï¼‰"""
    if not s:
        return ""
    s = re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+", "[redacted@email]", s)
    s = re.sub(r"\b\d{10,}\b", "[redacted-number]", s)
    return s

class TokenBucket:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«QPSåˆ¶å¾¡ï¼ˆç´ æœ´ãªãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚±ãƒƒãƒˆï¼‰"""
    def __init__(self, qps: float):
        self.interval = 1.0 / max(qps, 0.0001)
        self._lock = asyncio.Lock()
        self._next = time.monotonic()
    async def acquire(self):
        async with self._lock:
            now = time.monotonic()
            if now < self._next:
                await asyncio.sleep(self._next - now)
            self._next = max(now, self._next) + self.interval

# ====== DB =========================================================================
def ensure_tables(conn: sqlite3.Connection):
    """ã‚¹ã‚­ãƒ¼ãƒä½œæˆï¼ˆåŒ¿åã®ä¸€èˆ¬åï¼‰"""
    cur = conn.cursor()
    cur.execute("PRAGMA journal_mode=WAL;")
    cur.execute("PRAGMA synchronous=NORMAL;")
    conn.commit()

    # å–å¾—å¯¾è±¡ãƒªãƒ³ã‚¯ï¼ˆä¾‹ï¼šdate, code, name, member_urlï¼‰
    cur.execute("""
        CREATE TABLE IF NOT EXISTS consensus_links (
            target_date TEXT,
            code        TEXT,
            name        TEXT,
            member_url  TEXT,
            PRIMARY KEY (target_date, code)
        )
    """)

    # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆï¼ˆKPIï¼‹ãƒ†ã‚­ã‚¹ãƒˆï¼‰
    cur.execute("""
        CREATE TABLE IF NOT EXISTS gated_snapshots (
            target_date TEXT,
            code        TEXT,
            sales_growth TEXT,
            op_profit_growth TEXT,
            op_margin TEXT,
            roe TEXT,
            roa TEXT,
            equity_ratio TEXT,
            dividend_payout TEXT,
            overview_text TEXT,
            topics_text   TEXT,
            risks_text    TEXT,
            PRIMARY KEY (target_date, code)
        )
    """)
    conn.commit()

def resolve_target_date(conn: sqlite3.Connection, explicit: Optional[str]) -> Optional[str]:
    """æŒ‡å®šãªã‘ã‚Œã° consensus_links ã®æœ€æ–°æ—¥ä»˜ã‚’ä½¿ç”¨"""
    if explicit:
        datetime.datetime.strptime(explicit, "%Y%m%d")
        return explicit
    cur = conn.cursor()
    cur.execute("SELECT MAX(target_date) FROM consensus_links")
    row = cur.fetchone()
    td = row[0] if row else None
    if td:
        datetime.datetime.strptime(td, "%Y%m%d")
        return td
    return None

def load_targets(conn: sqlite3.Connection, target_date: str, mode: str) -> List[Tuple[str, str]]:
    """
    consensus_links(target_date, code, member_url) å‰æã€‚
      - mode='all'     : å…¨ä»¶
      - mode='missing' : ã¾ã  gated_snapshots ã«ç„¡ã„ã‚‚ã®
    è¨±å¯ã‚ªãƒªã‚¸ãƒ³ã§ãƒ•ã‚£ãƒ«ã‚¿ã€‚
    """
    cur = conn.cursor()
    if mode == "all":
        cur.execute("SELECT code, member_url FROM consensus_links WHERE target_date = ?", (target_date,))
        return [(c, u) for c, u in cur.fetchall() if u and is_allowed(u)]

    cur.execute("""
        SELECT code FROM consensus_links WHERE target_date = ?
        EXCEPT
        SELECT code FROM gated_snapshots WHERE target_date = ?
    """, (target_date, target_date))
    codes = [r[0] for r in cur.fetchall()]
    if not codes:
        return []
    ph = ",".join(["?"] * len(codes))
    cur.execute(f"""
        SELECT code, member_url FROM consensus_links
        WHERE target_date = ? AND code IN ({ph})
    """, [target_date] + codes)
    return [(c, u) for c, u in cur.fetchall() if u and is_allowed(u)]

# ====== Seleniumï¼ˆäººæ‰‹ãƒ­ã‚°ã‚¤ãƒ³ï¼‰ ====================================================
def build_selenium() -> Tuple[webdriver.Chrome, str]:
    """å¯è¦–ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•ï¼ˆdetach=True ã§çµ‚äº†å¾Œã‚‚ç”»é¢ã‚’æ®‹ã™ï¼‰"""
    opts = Options()
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_experimental_option("detach", True)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªã®ãŸã‚é–‹ã„ãŸã¾ã¾
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)
    opts.page_load_strategy = "eager"
    ua = "Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome Safari"
    opts.add_argument(f"user-agent={ua}")
    driver = webdriver.Chrome(service=Service(), options=opts)
    driver.set_page_load_timeout(SEL_NAV_TIMEOUT)
    return driver, ua

def site_login(driver: webdriver.Chrome, wait_seconds: int):
    """
    äººæ‰‹ãƒ­ã‚°ã‚¤ãƒ³ãŒå‰æã€‚ALLOW_AUTOFILL ã¨èªè¨¼æƒ…å ±ãŒã‚ã‚Œã°æœ€å°é™è£œåŠ©ã€‚
    å…·ä½“ã‚µã‚¤ãƒˆåã¯å‡ºã•ãªã„ã€‚è¦ç´ ã‚»ãƒ¬ã‚¯ã‚¿ã¯ä¸€èˆ¬çš„ãªä¾‹ã€‚
    """
    driver.get(LOGIN_URL)
    print("ğŸŒ ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§èªè¨¼ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")

    if ALLOW_AUTOMATION and ALLOW_AUTOFILL and USER_ID and PASSWORD:
        try:
            uid = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[name='username'], input[name='user_id']"))
            )
            pwd = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='password']"))
            )
            uid.clear(); uid.send_keys(USER_ID)
            pwd.clear(); pwd.send_keys(PASSWORD)
            btns = driver.find_elements(By.CSS_SELECTOR, "button[type='submit'], input[type='submit']")
            if btns:
                try:
                    btns[0].click()
                    print("ğŸ” èªè¨¼æƒ…å ±ã‚’é€ä¿¡ã—ã¾ã—ãŸï¼ˆALLOW_AUTOFILLï¼‰ã€‚è¿½åŠ èªè¨¼ãŒã‚ã‚Œã°äººæ‰‹ã§å®Ÿæ–½ã—ã¦ãã ã•ã„ã€‚")
                except Exception:
                    pass
        except Exception:
            pass

    if wait_seconds > 0:
        print(f"â³ æ‰‹å‹•èªè¨¼ã®ãŸã‚ {wait_seconds} ç§’ã»ã©å¾…æ©Ÿã—ã¾ã™ã€‚")
        time.sleep(wait_seconds)

    input("â¸ ä¼šå“¡ãƒšãƒ¼ã‚¸ã¸é·ç§»ã§ãã‚‹çŠ¶æ…‹ã«ãªã£ãŸã‚‰ Enter ã‚’æŠ¼ã—ã¦ãã ã•ã„â€¦ ")

def export_cookies_for_playwright(driver: webdriver.Chrome) -> List[Dict[str, Any]]:
    """Seleniumã®Cookieã‚’Playwrightã¸å—ã‘æ¸¡ã—ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³/ãƒ‘ã‚¹ã¯æ‹¡å¼µã—ãªã„ï¼‰"""
    cookies: List[Dict[str, Any]] = []
    for c in driver.get_cookies():
        cookies.append({
            "name": c.get("name"),
            "value": c.get("value"),
            "domain": c.get("domain"),
            "path": c.get("path", "/"),
            "expires": c.get("expiry", -1),
            "httpOnly": bool(c.get("httpOnly", False)),
            "secure": bool(c.get("secure", True)),
            "sameSite": "Lax",
        })
    return cookies

# ====== Playwrightï¼ˆå–å¾—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰ ==================================================
@asynccontextmanager
async def playwright_context(play, user_agent: str, seed_cookies: List[Dict[str, Any]], headful: bool):
    """Cookieã‚’æŠ•å…¥ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã€‚ç”»åƒ/ãƒ•ã‚©ãƒ³ãƒˆã¯é®æ–­ã—ã¦è»½é‡åŒ–ã€‚"""
    browser = await play.chromium.launch(
        headless=not headful,
        args=["--disable-gpu", "--disable-dev-shm-usage", "--no-sandbox"]
    )
    context = await browser.new_context(
        user_agent=user_agent,
        java_script_enabled=True,
        bypass_csp=True,
        viewport={"width": 1366, "height": 768}
    )

    async def route_handler(route, request):
        if request.resource_type in ("image", "media", "font"):
            await route.abort()
        else:
            await route.continue_()
    await context.route("**/*", route_handler)

    if seed_cookies:
        try:
            await context.add_cookies([c for c in seed_cookies if c.get("domain")])
        except Exception:
            # ã‚¯ãƒ­ã‚¹ã‚µã‚¤ãƒˆå±æ€§ç­‰ã¯æœ¬ãƒ‡ãƒ¢ã§ã¯ç„¡è¦–
            pass

    try:
        yield context
    finally:
        await context.close()
        await browser.close()

async def fetch_one(page: Page, code: str, url: str) -> Tuple[str, Dict[str, Any]]:
    """1ä»¶å–å¾—ï¼šãƒ€ãƒŸãƒ¼XPathã§KPIã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¡å–"""
    await page.goto(url, wait_until="domcontentloaded", timeout=NAV_TIMEOUT_MS)
    await page.wait_for_selector("xpath=//*[@id='metrics']", timeout=NAV_TIMEOUT_MS)  # è¦ªè¦ç´ ã®ãƒ¬ãƒ³ãƒ€å¾…ã¡
    data = await page.evaluate(
        """(xps)=>{
            const out = {};
            const get = (xp) => {
              try { return document.evaluate(xp, document, null, XPathResult.STRING_TYPE, null).stringValue.trim(); }
              catch(e){ return ""; }
            };
            for (const [k, xp] of Object.entries(xps)) out[k] = get(xp);
            return out;
        }""",
        XPATH_MAP
    )
    # æ•´å½¢ï¼ˆ%ä»˜ä¸ãƒ»ç©ºç™½åœ§ç¸®ï¼‰
    for k, v in list(data.items()):
        if k in ("sales_growth","op_profit_growth","op_margin","roe","roa","equity_ratio","dividend_payout"):
            data[k] = pct(v)
        else:
            data[k] = squeeze_ws(v)
    return code, data

async def worker(ctx, jobs: asyncio.Queue, bucket: TokenBucket, results: asyncio.Queue):
    """ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆä¿å®ˆçš„ãƒªãƒˆãƒ©ã‚¤ï¼‹QPSåˆ¶å¾¡ï¼‰"""
    page = await ctx.new_page()
    try:
        while True:
            item = await jobs.get()
            if item is None:
                break
            code, url = item
            await bucket.acquire()
            delay = BASE_DELAY
            last_err = None
            for attempt in range(RETRIES):
                try:
                    c, d = await fetch_one(page, code, url)
                    await results.put((c, d, None))
                    break
                except (PwTimeout, Exception) as e:
                    last_err = e
                    if attempt < RETRIES - 1:
                        await asyncio.sleep(delay); delay *= 1.8
                    else:
                        await results.put((code, None, last_err))
            jobs.task_done()
    finally:
        await page.close()

async def run_scrape(targets: List[Tuple[str, str]], ua: str, cookies: List[Dict[str, Any]],
                     target_date: str, qps: float, concurrency: int, batch: int, headful: bool):
    """Playwrightã§å¯¾è±¡ã‚’å·¡å›ã—ã¦DBã¸è“„ç©"""
    conn = sqlite3.connect(DB_PATH)
    ensure_tables(conn)
    cur = conn.cursor()

    jobs: asyncio.Queue = asyncio.Queue()
    results: asyncio.Queue = asyncio.Queue()
    for t in targets:
        await jobs.put(t)

    total = len(targets)
    done = ok = ng = 0
    buf: List[Tuple] = []
    bucket = TokenBucket(qps)

    async with async_playwright() as play:
        async with playwright_context(play, ua, cookies, headful=headful) as ctx:
            workers = [asyncio.create_task(worker(ctx, jobs, bucket, results))
                       for _ in range(max(1, min(concurrency, 4)))]

            async def stop_workers():
                for _ in workers:
                    await jobs.put(None)

            try:
                while done < total:
                    code, data, err = await results.get()
                    done += 1
                    if err is None and data:
                        row = (
                            target_date, code,
                            data.get("sales_growth",""), data.get("op_profit_growth",""),
                            data.get("op_margin",""), data.get("roe",""), data.get("roa",""),
                            data.get("equity_ratio",""), data.get("dividend_payout",""),
                            data.get("overview_text",""), data.get("topics_text",""), data.get("risks_text",""),
                        )
                        buf.append(row); ok += 1
                        if len(buf) >= batch:
                            cur.executemany("""
                                INSERT OR REPLACE INTO gated_snapshots (
                                    target_date, code,
                                    sales_growth, op_profit_growth, op_margin, roe, roa, equity_ratio, dividend_payout,
                                    overview_text, topics_text, risks_text
                                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            """, buf)
                            conn.commit(); buf.clear()
                    else:
                        ng += 1
                        err_msg = redact(str(err)) if err else ""
                        print(f"  âœ– {code}: {err_msg}")
                    if done % 50 == 0 or done == total:
                        print(f"ğŸ“¦ {done}/{total}  OK:{ok}  NG:{ng}")
            finally:
                if buf:
                    cur.executemany("""
                        INSERT OR REPLACE INTO gated_snapshots (
                            target_date, code,
                            sales_growth, op_profit_growth, op_margin, roe, roa, equity_ratio, dividend_payout,
                            overview_text, topics_text, risks_text
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    """, buf)
                    conn.commit()
                await stop_workers()
                await asyncio.gather(*workers, return_exceptions=True)
                conn.close()
                print(f"ğŸ å®Œäº† / OK:{ok} NG:{ng} / å¯¾è±¡:{total}")

# ====== ãƒ¡ã‚¤ãƒ³ ======================================================================
def print_policy_banner():
    print("\n" + "="*78)
    print("  ã€ãƒãƒªã‚·ãƒ¼/å®‰å…¨ãƒãƒŠãƒ¼ã€‘")
    print("- æ¨©é™ãŒã‚ã‚‹ã‚µã‚¤ãƒˆã®ã¿ã§åˆ©ç”¨ï¼ˆç¬¬ä¸‰è€…ã‚µã‚¤ãƒˆã®è¦ç´„ãƒ»æ³•ä»¤ãƒ»robotsç­‰ã‚’é †å®ˆï¼‰ã€‚")
    print("- ãƒ­ã‚°ã‚¤ãƒ³ã¯å¯è¦–ãƒ–ãƒ©ã‚¦ã‚¶ã§äººæ‰‹ç¢ºèªã€‚è‡ªå‹•å…¥åŠ›ã¯æ˜ç¤ºã‚ªãƒ—ãƒˆã‚¤ãƒ³æ™‚ã®ã¿ã€‚")
    print("- æœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯èªè¨¼æƒ…å ±/PII/Cookieã‚’ãƒ‡ã‚£ã‚¹ã‚¯ä¿å­˜ã—ã¾ã›ã‚“ã€‚")
    print("- ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ãƒ»ä¿å®ˆçš„ãªãƒªãƒˆãƒ©ã‚¤ã§éè² è·ã‚’å›é¿ã—ã¾ã™ã€‚")
    print("="*78 + "\n")

def main():
    print_policy_banner()

    p = argparse.ArgumentParser(
        description="ä¼šå“¡ã‚µã‚¤ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³â†’ç¯€åº¦ã‚ã‚‹QPSã§ãƒ¡ãƒ³ãƒãƒ¼ãƒšãƒ¼ã‚¸ã‚’å·¡å›ã—ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ï¼ˆåŒ¿åãƒ»è¦ç´„é…æ…®ã®é››å½¢ï¼‰"
    )
    p.add_argument("-a", "--target_date", help="YYYYMMDDï¼ˆæœªæŒ‡å®šã¯ consensus_links ã®æœ€æ–°æ—¥ä»˜ï¼‰")
    p.add_argument("--mode", choices=["all", "missing"], default="missing",
                   help="all: è©²å½“æ—¥ã®å…¨ã‚³ãƒ¼ãƒ‰ / missing: æœªå–å¾—ã®ã¿")
    p.add_argument("--qps", type=float, default=DEFAULT_QPS, help="å…¨ä½“QPSï¼ˆ0.5ã€œ0.9æ¨å¥¨ï¼‰")
    p.add_argument("--concurrency", type=int, default=DEFAULT_CONCURRENCY, help="Playwrightä¸¦åˆ—ï¼ˆ1ã€œ4æ¨å¥¨ï¼‰")
    p.add_argument("--batch", type=int, default=DEFAULT_BATCH, help="DBã‚³ãƒŸãƒƒãƒˆé–“éš”")
    p.add_argument("--login-wait", type=int, default=DEFAULT_LOGIN_WAIT, help="åˆå›ãƒ­ã‚°ã‚¤ãƒ³å¾Œã«å¾…æ©Ÿã™ã‚‹ç§’æ•°ï¼ˆäººæ‰‹èªè¨¼ç”¨ã®ç›®å®‰ï¼‰")
    p.add_argument("--headful", action="store_true", help="Playwrightã‚‚å¯è¦–åŒ–ï¼ˆãƒ‡ãƒ¢/ãƒ‡ãƒãƒƒã‚°ï¼‰")
    args = p.parse_args()

    if not ALLOW_AUTOMATION:
        print("âš ï¸ è‡ªå‹•åŒ–ã¯ç„¡åŠ¹ã§ã™ã€‚ç’°å¢ƒå¤‰æ•° ALLOW_AUTOMATION=1 ã‚’è¨­å®šã—ã¦æ˜ç¤ºçš„ã«è¨±å¯ã—ã¦ãã ã•ã„ã€‚")
        sys.exit(0)

    # DBã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè§£æ±º
    conn = sqlite3.connect(DB_PATH)
    ensure_tables(conn)
    target_date = resolve_target_date(conn, args.target_date)
    if not target_date:
        print("âŒ target_date ã‚’æ±ºå®šã§ãã¾ã›ã‚“ã€‚-a YYYYMMDD ã‚’æŒ‡å®šã™ã‚‹ã‹ã€consensus_links ã‚’äº‹å‰ã«æŠ•å…¥ã—ã¦ãã ã•ã„ã€‚")
        conn.close(); sys.exit(1)

    targets = load_targets(conn, target_date, args.mode)
    if not targets:
        msg = "æœªå–å¾—ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆmode=missingï¼‰" if args.mode == "missing" else "å¯¾è±¡URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆmode=allï¼‰"
        print(f"â„¹ï¸ {target_date} {msg}")
        conn.close(); return
    conn.close()

    # 1) Seleniumã§äººæ‰‹ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ã¯é–‹ã„ãŸã¾ã¾ï¼‰
    print("ğŸŒ Seleniumã§å¯è¦–ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚")
    driver, ua = build_selenium()
    try:
        site_login(driver, wait_seconds=args.login_wait)
        cookies = export_cookies_for_playwright(driver)
        if not cookies:
            print("âš ï¸ Cookieã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœªèªè¨¼ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç¶šè¡Œå¯ã ãŒå¤±æ•—ã™ã‚‹å ´åˆã‚ã‚Šï¼‰ã€‚")
    finally:
        # ãƒ‡ãƒ¢ã®ãŸã‚ãƒ–ãƒ©ã‚¦ã‚¶ã¯é–‹ã„ãŸã¾ã¾ï¼ˆé€æ˜æ€§ç¢ºä¿ï¼‰ã€‚ã“ã“ã§ã¯ quit ã—ãªã„ã€‚
        pass

    # 2) Playwrightã§ç¯€åº¦ã‚ã‚‹å·¡å›å–å¾—
    print(f"â–¶ å–å¾—é–‹å§‹: mode={args.mode} date={target_date} / concurrency={args.concurrency} qps={args.qps}")
    asyncio.run(run_scrape(
        targets=targets,
        ua=ua,
        cookies=cookies,
        target_date=target_date,
        qps=args.qps,
        concurrency=args.concurrency,
        batch=args.batch,
        headful=args.headful
    ))

    print("\nğŸ§¹ Seleniumã®ãƒ­ã‚°ã‚¤ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯å¯è¦–ã®ã¾ã¾ã§ã™ã€‚ä½œæ¥­å®Œäº†å¾Œã«æ‰‹å‹•ã§é–‰ã˜ã¦ãã ã•ã„ã€‚")
    print("   â€» æœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯èªè¨¼æƒ…å ±ãƒ»Cookieãƒ»å€‹äººæƒ…å ±ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã¸ä¿å­˜ã—ã¾ã›ã‚“ã€‚")

if __name__ == "__main__":
    main()
